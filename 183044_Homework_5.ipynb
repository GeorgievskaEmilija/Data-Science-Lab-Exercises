{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "183044_Homework-5.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5a9f86de86a844b898c6f6964a2e1d20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_71a1e51334b148b6a366dae75d5978b2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d75546bc627d412abd88021886a7ec3c",
              "IPY_MODEL_cf35e5bc9b6f4681b1d6273f5ca576fa"
            ]
          }
        },
        "71a1e51334b148b6a366dae75d5978b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d75546bc627d412abd88021886a7ec3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1d979e7c6fbb41a7a1a64964dabf5b55",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_24955abf8c964edc82f62a4ce6a67018"
          }
        },
        "cf35e5bc9b6f4681b1d6273f5ca576fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bb8fdef6f9ae4e32851b9adffe9d7a26",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 3.15kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e1dd0991907d40ada4bcd8b8da06089d"
          }
        },
        "1d979e7c6fbb41a7a1a64964dabf5b55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "24955abf8c964edc82f62a4ce6a67018": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bb8fdef6f9ae4e32851b9adffe9d7a26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e1dd0991907d40ada4bcd8b8da06089d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8eee096fb24b4b9eb6e5cf6b49af185b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_34d1bca29bb346458bf4ca66c37f659a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_af9f3d2b29804c969dec834444631194",
              "IPY_MODEL_4c603152ea374a1eb70bc9c444fe7140"
            ]
          }
        },
        "34d1bca29bb346458bf4ca66c37f659a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "af9f3d2b29804c969dec834444631194": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e3cd1a1a99ba43e29751522d6af1b25b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d1f5f725ca314522a500abe833efa366"
          }
        },
        "4c603152ea374a1eb70bc9c444fe7140": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2d1adcad72ed4a6aa32c0294eff74dc0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:09&lt;00:00, 45.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_76c2f25475634b5facd0cd82a54542f9"
          }
        },
        "e3cd1a1a99ba43e29751522d6af1b25b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d1f5f725ca314522a500abe833efa366": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2d1adcad72ed4a6aa32c0294eff74dc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "76c2f25475634b5facd0cd82a54542f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "72531f336b6a47f2b24e9b2db9012766": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ce3500d79f3a4f64909ec7cadfa771fd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f7e3c265e3e34f2e851123792f5c0a2e",
              "IPY_MODEL_bde6f94953a44e5f8b5b244531995171"
            ]
          }
        },
        "ce3500d79f3a4f64909ec7cadfa771fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f7e3c265e3e34f2e851123792f5c0a2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ac9c369a3cab4b7c8ee76eba3fc42446",
            "_dom_classes": [],
            "description": "  0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_961d5ad2dd0440008b6d8cc4e389bb85"
          }
        },
        "bde6f94953a44e5f8b5b244531995171": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_085cefd98ee14ce9ad4f4ea27c2c7530",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/1 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_930a9c78ce55442ea7ecea642f96ccca"
          }
        },
        "ac9c369a3cab4b7c8ee76eba3fc42446": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "961d5ad2dd0440008b6d8cc4e389bb85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "085cefd98ee14ce9ad4f4ea27c2c7530": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "930a9c78ce55442ea7ecea642f96ccca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f1557024adf24d25b2de01c994b9984d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0772b5515f5e4e62a4fc4eb32a94593d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c2b03216c9ba4ec7b2799f0b6817e019",
              "IPY_MODEL_e6f07915d7af4ca68f683dc625956b89"
            ]
          }
        },
        "0772b5515f5e4e62a4fc4eb32a94593d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c2b03216c9ba4ec7b2799f0b6817e019": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_21b05171a7854e46a4d20e21d7abbefa",
            "_dom_classes": [],
            "description": "Epoch 1:  14%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1618,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 230,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cc89cc57b36e487683ec6131306d7881"
          }
        },
        "e6f07915d7af4ca68f683dc625956b89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_44ad8887d2124502a1576a3d17244caf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 230/1618 [45:21&lt;4:31:45, 11.75s/it, training_loss=0.058]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_63ead6a3ace5458585f8b2a4250e293a"
          }
        },
        "21b05171a7854e46a4d20e21d7abbefa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cc89cc57b36e487683ec6131306d7881": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "44ad8887d2124502a1576a3d17244caf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "63ead6a3ace5458585f8b2a4250e293a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GeorgievskaEmilija/Data-Science-Lab-Exercises/blob/main/183044_Homework_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4CnlFmQnf7j"
      },
      "source": [
        "\n",
        "<font size = 4 color='Orange'>\n",
        "Learning Goals</font>\n",
        "\n",
        "<font color = 'Orange' size = 3 >In this Exercise your goal is to make a good solution for the active competition on kaggle: https://www.kaggle.com/c/nlp-getting-started/overview\n",
        "\n",
        "<font color = 'Orange' size = 3 > In order to download the Datasets you will need to join and accept the terms and conditions of the competition. </foont>\n",
        "\n",
        "You need to report the parameters for the best three models into a table that will contain the model architecture and F1 score.\n",
        "</font>\n",
        "\n",
        "<font color = 'Orange' size = 4 > Structure of the Dataset </font>\n",
        "\n",
        "<font color = 'Orange' size = 3>\n",
        "The Dataset it's divided on two parts for training and testing. For the testing part you need to map the id's with the sample_submission.csv, where the target column is located.</li>\n",
        "</font>\n",
        "\n",
        "<font color = 'Orange' size = 4 >Instructions</font>\n",
        "<ul>\n",
        "<font color = 'Orange'>\n",
        "Try to train different kinds of NN's structures\n",
        "\n",
        "<li>Choose the number of layers your model will have</li>\n",
        "<li>Add Embedding Layer for the text</li>\n",
        "<li>Choose the types of layers your model will have: CNN, LSTM, GRU, RNN, Dense,...</li>\n",
        "<li>Choose the number of neurons in each hidden layer</li>\n",
        "<li>Choose activation function for each layer: relu, sigmoid, softmax, softsign, linear,... </li>\n",
        "<li>Choose the loss function for compiling: mean_squared_error, mean_absolute_error, root_mean_squared_error,....</li>\n",
        "<li>Choose the optimizer function for compiling: adam, adagrad, adamax, sgd,....</li>\n",
        "<li>Choose the number of epochs and the batch size for the training part</li>\n",
        "</ul>\n",
        "\n",
        "</font>\n",
        "<font color = 'Orange' size = 4 >\n",
        "Report the parameters of the three best models in a table with the given columns:\n",
        "</font>\n",
        "<ul>\n",
        "<font color = 'Orange'>\n",
        "<li>Number of the model</li>\n",
        "<li>Number of layers</li>\n",
        "<li>Types of layers</li>\n",
        "<li>Activation function for each layer</li>\n",
        "<li>Number of epochs</li>\n",
        "<li>Batch size</li>\n",
        "<li>Loss function</li>\n",
        "<li>Optimizer function for compiling</li>\n",
        "<li>F1 score for the prediction of the test part (this is the metric for rating the models)</li>\n",
        "</ul>\n",
        "<font color = 'Orange' size = 4 >Transformers based models</font>\n",
        "\n",
        "<font color = 'Orange' size = 3 > Create a model that will use some of the pretrained BERT, RoBERTa, XLNet, XLM ... models for Text Classification [Hugging Face](https://huggingface.co/transformers/quicktour.html). \n",
        "\n",
        "Report the following parameters for models based on Transformers</font>\n",
        "<ul>\n",
        "<font color='orange'>\n",
        "<li> Pretrained model</li>\n",
        "\n",
        "<li>Loss function</li>\n",
        "<li>Optimizer function for compiling</li>\n",
        "<li>F1 score for the prediction of the test part (this is the metric for rating the models)\n",
        "</li>\n",
        "\n",
        "</ul>\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5fgr8yJzTUJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "782d719d-01a4-48b3-e314-f9ebbf5fc611"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1q0Zwb5W-4y_"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "train = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/train.csv\")\n",
        "test = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/test.csv\")\n",
        "sample_submission=pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/sample_submission.csv\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "CFHPF7UcC255",
        "outputId": "20e7d654-d741-4119-c0db-ac355eef378b"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword  ...                                               text target\n",
              "0   1     NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n",
              "1   4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n",
              "2   5     NaN  ...  All residents asked to 'shelter in place' are ...      1\n",
              "3   6     NaN  ...  13,000 people receive #wildfires evacuation or...      1\n",
              "4   7     NaN  ...  Just got sent this photo from Ruby #Alaska as ...      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "HbZQ9fIV_h83",
        "outputId": "29018510-b260-4e5b-d111-537195f9e9f3"
      },
      "source": [
        "test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword location                                               text\n",
              "0   0     NaN      NaN                 Just happened a terrible car crash\n",
              "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
              "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
              "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
              "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "yeZIPA65C_TX",
        "outputId": "4360a797-eb34-49ae-d93b-3c460aa3a993"
      },
      "source": [
        "sample_submission.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  target\n",
              "0   0       0\n",
              "1   2       0\n",
              "2   3       0\n",
              "3   9       0\n",
              "4  11       0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JIc7yAaDG9_"
      },
      "source": [
        "train.drop(columns=['keyword', 'location'], axis=1, inplace=True)\n",
        "test.drop(columns=['keyword', 'location'], axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2GZ4X08GYSn"
      },
      "source": [
        "test=pd.merge(test, sample_submission,how=\"left\", on='id')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "hb_PYtzRGer5",
        "outputId": "6338c13b-acd5-41c9-989f-9ef102aeab8d"
      },
      "source": [
        "test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id                                               text  target\n",
              "0   0                 Just happened a terrible car crash       0\n",
              "1   2  Heard about #earthquake is different cities, s...       0\n",
              "2   3  there is a forest fire at spot pond, geese are...       0\n",
              "3   9           Apocalypse lighting. #Spokane #wildfires       0\n",
              "4  11      Typhoon Soudelor kills 28 in China and Taiwan       0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZL0sjK2GuSb"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = train['text']\n",
        "Y = pd.get_dummies(train['target']).values\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.2, random_state=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s44U2IzRLfjG"
      },
      "source": [
        "from keras_preprocessing.text import Tokenizer\n",
        "\n",
        "max_features = 20000\n",
        "\n",
        "tokenizer = Tokenizer(num_words = max_features)\n",
        "tokenizer.fit_on_texts(list(X_train))\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "rLvXipSwL3g0",
        "outputId": "2e0f4f5b-4b0c-4101-e2d3-d3a1736b97de"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "totalNumWords = [len(text) for text in X_train]\n",
        "plt.hist(totalNumWords,bins = 30)\n",
        "plt.show()\n",
        "maxWords=max(totalNumWords)\n",
        "print(\"MAX WORDS IN ONE TEXT: \" ,maxWords)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "MAX WORDS IN ONE TEXT:  33\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZuoIXeWPQIQ"
      },
      "source": [
        "from keras.preprocessing import sequence\n",
        "maxWords = 40 #da se ostavi malku prostor \n",
        "X_train = sequence.pad_sequences(X_train, maxlen=maxWords)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=maxWords)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SyFyEBHQNuo"
      },
      "source": [
        "import keras.backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Embedding,Conv1D,MaxPooling1D,LSTM, Flatten\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "from collections import OrderedDict\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVueLp1xRYHp",
        "outputId": "eb6e0bf5-1d66-4c73-a8c2-1c524f69f25b"
      },
      "source": [
        "#MODEL 1\n",
        "\n",
        "K.clear_session()\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(max_features, 110, input_length=X_train.shape[1]))\n",
        "model.add(Conv1D(filters=30, kernel_size=3, padding='same', activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Conv1D(filters=30, kernel_size=3, padding='same', activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))    \n",
        "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "#kompajliranje\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "#istorija\n",
        "model_history = model.fit(X_train, Y_train,  epochs=6, batch_size=80, verbose=2, validation_split=0.2)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = y_pred\n",
        "score = f1_score(np.argmax(Y_test,axis=1), np.argmax(y_pred,axis=1))\n",
        "\n",
        "#dict\n",
        "modeldict1=OrderedDict()\n",
        "modeldict1[\"Model no\"] = 1\n",
        "modeldict1[\"Number of layers\"] = 7\n",
        "modeldict1['Layer type and activation'] = ['1: Embedding', '2: Conv1d - relu', '3: MaxPooling1D', '4: Conv1d - relu', '5: MaxPooling1D', '6: LSTM', '7: Dense - softmax']\n",
        "modeldict1['Epochs'] = 6\n",
        "modeldict1['Batch size'] = 80\n",
        "modeldict1['Loss func'] = 'categorical_crossentropy'\n",
        "modeldict1['Optimizer'] = 'adam'\n",
        "modeldict1['F1 Score']=score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "61/61 - 7s - loss: 0.6505 - accuracy: 0.6024 - val_loss: 0.5439 - val_accuracy: 0.7307\n",
            "Epoch 2/6\n",
            "61/61 - 4s - loss: 0.3747 - accuracy: 0.8413 - val_loss: 0.4473 - val_accuracy: 0.8005\n",
            "Epoch 3/6\n",
            "61/61 - 4s - loss: 0.1401 - accuracy: 0.9514 - val_loss: 0.5615 - val_accuracy: 0.7972\n",
            "Epoch 4/6\n",
            "61/61 - 4s - loss: 0.0545 - accuracy: 0.9840 - val_loss: 0.6967 - val_accuracy: 0.7783\n",
            "Epoch 5/6\n",
            "61/61 - 4s - loss: 0.0306 - accuracy: 0.9916 - val_loss: 0.8302 - val_accuracy: 0.7915\n",
            "Epoch 6/6\n",
            "61/61 - 4s - loss: 0.0184 - accuracy: 0.9947 - val_loss: 0.8195 - val_accuracy: 0.7816\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Owa0HyQUYnjM",
        "outputId": "baec8ca1-3c06-477a-b8f7-268042463a26"
      },
      "source": [
        "#MODEL 2\n",
        "\n",
        "K.clear_session()\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(max_features, 150, input_length=X_train.shape[1]))\n",
        "model.add(Conv1D(filters=25, kernel_size=3, padding='same', activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Conv1D(filters=25, kernel_size=3, padding='same', activation='relu'))\n",
        "model.add(LSTM(120, dropout=0.1, recurrent_dropout=0.2))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "#kompajliranje\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "#istorija\n",
        "model_history = model.fit(X_train, Y_train,  epochs=7, batch_size=90, verbose=2, validation_split=0.2)\n",
        "\n",
        "y_pred2 = model.predict(X_test)\n",
        "y_pred2 = y_pred2\n",
        "score = f1_score(np.argmax(Y_test,axis=1), np.argmax(y_pred2,axis=1))\n",
        "\n",
        "#dict\n",
        "modeldict2=OrderedDict()\n",
        "modeldict2[\"Model no\"] = 2\n",
        "modeldict2[\"Number of layers\"] = 6\n",
        "modeldict2['Layer type and activation'] = ['1: Embedding', '2: Conv1d - relu', '3: MaxPooling1D', '4: Conv1d - relu',  '5: LSTM', '6: Dense - softmax']\n",
        "modeldict2['Epochs'] = 7\n",
        "modeldict2['Batch size'] = 90\n",
        "modeldict2['Loss func'] = 'categorical_crossentropy'\n",
        "modeldict2['Optimizer'] = 'adam'\n",
        "modeldict2['F1 Score']=score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/7\n",
            "55/55 - 9s - loss: 0.6357 - accuracy: 0.6223 - val_loss: 0.5133 - val_accuracy: 0.7455\n",
            "Epoch 2/7\n",
            "55/55 - 6s - loss: 0.3102 - accuracy: 0.8781 - val_loss: 0.5049 - val_accuracy: 0.7898\n",
            "Epoch 3/7\n",
            "55/55 - 6s - loss: 0.1153 - accuracy: 0.9631 - val_loss: 0.6223 - val_accuracy: 0.7258\n",
            "Epoch 4/7\n",
            "55/55 - 6s - loss: 0.0591 - accuracy: 0.9832 - val_loss: 0.7008 - val_accuracy: 0.7791\n",
            "Epoch 5/7\n",
            "55/55 - 6s - loss: 0.0357 - accuracy: 0.9897 - val_loss: 0.8440 - val_accuracy: 0.7504\n",
            "Epoch 6/7\n",
            "55/55 - 6s - loss: 0.0256 - accuracy: 0.9932 - val_loss: 0.8229 - val_accuracy: 0.7315\n",
            "Epoch 7/7\n",
            "55/55 - 6s - loss: 0.0190 - accuracy: 0.9934 - val_loss: 0.7927 - val_accuracy: 0.7562\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wBIKUjWbhsq",
        "outputId": "865b2f49-79a6-4aac-db06-0656923e4c2c"
      },
      "source": [
        "#MODEL 3\n",
        "\n",
        "K.clear_session()\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(max_features, 120, input_length=X_train.shape[1]))\n",
        "model.add(Conv1D(filters=40, kernel_size=3, padding='same', activation='relu'))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Conv1D(filters=20, kernel_size=3, padding='same', activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Conv1D(filters=10, kernel_size=3, padding='same', activation='softmax'))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(LSTM(30, dropout=0.1, recurrent_dropout=0.1))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "#kompajliranje\n",
        "model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
        "#istorija\n",
        "model_history = model.fit(X_train, Y_train,  epochs=8, batch_size=150, verbose=2, validation_split=0.2)\n",
        "\n",
        "y_pred3 = model.predict(X_test)\n",
        "y_pred3 = y_pred3.round()\n",
        "\n",
        "score = f1_score(np.argmax(Y_test,axis=1), np.argmax(y_pred3,axis=1))\n",
        "\n",
        "#dict\n",
        "modeldict3=OrderedDict()\n",
        "modeldict3[\"Model no\"] = 3\n",
        "modeldict3[\"Number of layers\"] = 11\n",
        "modeldict3['Layer type and activation'] = ['1: Embedding', '2: Conv1d - relu', '3: Dense - Relu',  '4: MaxPooling1D',   '5: Conv1d - relu', '6: MaxPooling1D',\n",
        "                                           '7: Conv1d - softmax','8: Dense - relu', '9: MaxPooling1D', '10: LSTM', '11: Dense - softmax']\n",
        "modeldict3['Epochs'] = 8\n",
        "modeldict3['Batch size'] = 150\n",
        "modeldict3['Loss func'] = 'mse'\n",
        "modeldict3['Optimizer'] = 'adam'\n",
        "modeldict3['F1 Score']=score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/8\n",
            "33/33 - 6s - loss: 0.2452 - accuracy: 0.5720 - val_loss: 0.2475 - val_accuracy: 0.5525\n",
            "Epoch 2/8\n",
            "33/33 - 3s - loss: 0.2449 - accuracy: 0.5720 - val_loss: 0.2470 - val_accuracy: 0.5525\n",
            "Epoch 3/8\n",
            "33/33 - 3s - loss: 0.2345 - accuracy: 0.5796 - val_loss: 0.2102 - val_accuracy: 0.7028\n",
            "Epoch 4/8\n",
            "33/33 - 3s - loss: 0.1263 - accuracy: 0.8452 - val_loss: 0.1727 - val_accuracy: 0.7521\n",
            "Epoch 5/8\n",
            "33/33 - 3s - loss: 0.0431 - accuracy: 0.9452 - val_loss: 0.1775 - val_accuracy: 0.7775\n",
            "Epoch 6/8\n",
            "33/33 - 3s - loss: 0.0205 - accuracy: 0.9762 - val_loss: 0.1975 - val_accuracy: 0.7471\n",
            "Epoch 7/8\n",
            "33/33 - 3s - loss: 0.0124 - accuracy: 0.9865 - val_loss: 0.2046 - val_accuracy: 0.7447\n",
            "Epoch 8/8\n",
            "33/33 - 3s - loss: 0.0083 - accuracy: 0.9910 - val_loss: 0.2060 - val_accuracy: 0.7438\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8sF5wXflisX",
        "outputId": "56012ee0-38ee-49cd-c072-b5d9bba8dc31"
      },
      "source": [
        "#MODEL 4\n",
        "\n",
        "K.clear_session()\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(max_features, 120, input_length=X_train.shape[1]))\n",
        "model.add(Conv1D(filters=40, kernel_size=3, padding='same', activation='softmax'))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(LSTM(30, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "#kompajliranje\n",
        "model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
        "#istorija\n",
        "model_history = model.fit(X_train, Y_train,  epochs=10, batch_size=200, verbose=2, validation_split=0.2)\n",
        "\n",
        "y_pred4 = model.predict(X_test)\n",
        "y_pred4 = y_pred4.round()\n",
        "\n",
        "score = f1_score(np.argmax(Y_test,axis=1), np.argmax(y_pred4,axis=1))\n",
        "\n",
        "#dict\n",
        "modeldict4=OrderedDict()\n",
        "modeldict4[\"Model no\"] = 4\n",
        "modeldict4[\"Number of layers\"] = 11\n",
        "modeldict4['Layer type and activation'] = ['1: Embedding', '2: Conv1d - softmax', '3: Dense - Relu',  '4: Dense - Relu',   '5: MaxPooling1D', '6: LSTM',\n",
        "                                           '7: Dense - softmax']\n",
        "modeldict4['Epochs'] = 10\n",
        "modeldict4['Batch size'] = 200\n",
        "modeldict4['Loss func'] = 'mse'\n",
        "modeldict4['Optimizer'] = 'adam'\n",
        "modeldict4['F1 Score']=score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "25/25 - 6s - loss: 0.2465 - accuracy: 0.5610 - val_loss: 0.2480 - val_accuracy: 0.5525\n",
            "Epoch 2/10\n",
            "25/25 - 3s - loss: 0.2446 - accuracy: 0.5720 - val_loss: 0.2468 - val_accuracy: 0.5525\n",
            "Epoch 3/10\n",
            "25/25 - 3s - loss: 0.2418 - accuracy: 0.5720 - val_loss: 0.2375 - val_accuracy: 0.5525\n",
            "Epoch 4/10\n",
            "25/25 - 3s - loss: 0.2085 - accuracy: 0.6624 - val_loss: 0.1908 - val_accuracy: 0.7126\n",
            "Epoch 5/10\n",
            "25/25 - 3s - loss: 0.1443 - accuracy: 0.8009 - val_loss: 0.1654 - val_accuracy: 0.7627\n",
            "Epoch 6/10\n",
            "25/25 - 3s - loss: 0.0776 - accuracy: 0.9000 - val_loss: 0.1677 - val_accuracy: 0.7611\n",
            "Epoch 7/10\n",
            "25/25 - 3s - loss: 0.0380 - accuracy: 0.9505 - val_loss: 0.1733 - val_accuracy: 0.7635\n",
            "Epoch 8/10\n",
            "25/25 - 3s - loss: 0.0254 - accuracy: 0.9713 - val_loss: 0.1726 - val_accuracy: 0.7718\n",
            "Epoch 9/10\n",
            "25/25 - 3s - loss: 0.0171 - accuracy: 0.9805 - val_loss: 0.1842 - val_accuracy: 0.7652\n",
            "Epoch 10/10\n",
            "25/25 - 3s - loss: 0.0129 - accuracy: 0.9856 - val_loss: 0.1827 - val_accuracy: 0.7742\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jg9TQ0mmb14",
        "outputId": "945aebca-ff3e-427e-9769-66c404513104"
      },
      "source": [
        "#MODEL 5\n",
        "\n",
        "K.clear_session()\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(max_features, 100, input_length=X_train.shape[1]))\n",
        "model.add(Conv1D(filters=15, kernel_size=3, padding='same', activation='relu'))\n",
        "model.add(LSTM(30, dropout=0.1, recurrent_dropout=0.1))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(2, activation='relu'))\n",
        "\n",
        "#kompajliranje\n",
        "model.compile(loss='mse', optimizer='adamax', metrics=['accuracy'])\n",
        "#istorija\n",
        "model_history = model.fit(X_train, Y_train,  epochs=9, batch_size=220, verbose=2, validation_split=0.2)\n",
        "\n",
        "y_pred5 = model.predict(X_test)\n",
        "y_pred5 = y_pred5.round()\n",
        "\n",
        "score = f1_score(np.argmax(Y_test,axis=1), np.argmax(y_pred4,axis=1))\n",
        "\n",
        "#dict\n",
        "modeldict5=OrderedDict()\n",
        "modeldict5[\"Model no\"] = 5\n",
        "modeldict5[\"Number of layers\"] = 11\n",
        "modeldict5['Layer type and activation'] = ['1: Embedding', '2: Conv1d - relu', '3: LSTM',  '4: Dense - Relu',   '5: Dense - relu']\n",
        "modeldict5['Epochs'] = 9\n",
        "modeldict5['Batch size'] = 220\n",
        "modeldict5['Loss func'] = 'mse'\n",
        "modeldict5['Optimizer'] = 'adamax'\n",
        "modeldict5['F1 Score']=score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/9\n",
            "23/23 - 5s - loss: 0.4248 - accuracy: 0.4308 - val_loss: 0.2971 - val_accuracy: 0.4475\n",
            "Epoch 2/9\n",
            "23/23 - 2s - loss: 0.2579 - accuracy: 0.5273 - val_loss: 0.2487 - val_accuracy: 0.5525\n",
            "Epoch 3/9\n",
            "23/23 - 2s - loss: 0.2421 - accuracy: 0.5720 - val_loss: 0.2404 - val_accuracy: 0.5525\n",
            "Epoch 4/9\n",
            "23/23 - 2s - loss: 0.2328 - accuracy: 0.6016 - val_loss: 0.2299 - val_accuracy: 0.5747\n",
            "Epoch 5/9\n",
            "23/23 - 2s - loss: 0.2172 - accuracy: 0.6539 - val_loss: 0.2121 - val_accuracy: 0.6667\n",
            "Epoch 6/9\n",
            "23/23 - 2s - loss: 0.1978 - accuracy: 0.6958 - val_loss: 0.1965 - val_accuracy: 0.6897\n",
            "Epoch 7/9\n",
            "23/23 - 2s - loss: 0.1724 - accuracy: 0.7551 - val_loss: 0.1755 - val_accuracy: 0.7422\n",
            "Epoch 8/9\n",
            "23/23 - 2s - loss: 0.1388 - accuracy: 0.8177 - val_loss: 0.1591 - val_accuracy: 0.7750\n",
            "Epoch 9/9\n",
            "23/23 - 2s - loss: 0.1146 - accuracy: 0.8502 - val_loss: 0.1525 - val_accuracy: 0.7964\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "UFZAr4SmnI1J",
        "outputId": "b9168eb0-5755-4e61-8e93-b119580ae03a"
      },
      "source": [
        "from operator import itemgetter\n",
        "allmodels=[]\n",
        "allmodels.append(modeldict1)\n",
        "allmodels.append(modeldict2)\n",
        "allmodels.append(modeldict3)\n",
        "allmodels.append(modeldict4)\n",
        "allmodels.append(modeldict5)\n",
        "\n",
        "newlist = sorted(allmodels, key=lambda k: k['F1 Score'],reverse=True) \n",
        "best=newlist[:3]\n",
        "\n",
        "matrix = []\n",
        "for i in range(0,3):\n",
        "  matrix.append(list(best[i].values()))\n",
        "df = pd.DataFrame(np.array(matrix), columns=list(modeldict1.keys()))\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  from ipykernel import kernelapp as app\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model no</th>\n",
              "      <th>Number of layers</th>\n",
              "      <th>Layer type and activation</th>\n",
              "      <th>Epochs</th>\n",
              "      <th>Batch size</th>\n",
              "      <th>Loss func</th>\n",
              "      <th>Optimizer</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>[1: Embedding, 2: Conv1d - relu, 3: MaxPooling...</td>\n",
              "      <td>6</td>\n",
              "      <td>80</td>\n",
              "      <td>categorical_crossentropy</td>\n",
              "      <td>adam</td>\n",
              "      <td>0.710717</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "      <td>[1: Embedding, 2: Conv1d - relu, 3: Dense - Re...</td>\n",
              "      <td>8</td>\n",
              "      <td>150</td>\n",
              "      <td>mse</td>\n",
              "      <td>adam</td>\n",
              "      <td>0.699377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "      <td>[1: Embedding, 2: Conv1d - softmax, 3: Dense -...</td>\n",
              "      <td>10</td>\n",
              "      <td>200</td>\n",
              "      <td>mse</td>\n",
              "      <td>adam</td>\n",
              "      <td>0.692241</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Model no Number of layers  ... Optimizer  F1 Score\n",
              "0        1                7  ...      adam  0.710717\n",
              "1        3               11  ...      adam  0.699377\n",
              "2        4               11  ...      adam  0.692241\n",
              "\n",
              "[3 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vawh6xCCqknZ"
      },
      "source": [
        "**TRANSFORMERS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y54AXMYZqkEZ",
        "outputId": "5c6363d2-ba67-47c7-fc78-0e40dc7dedff"
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/0c/7d5950fcd80b029be0a8891727ba21e0cd27692c407c51261c3c921f6da3/transformers-4.1.1-py3-none-any.whl (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 7.3MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 27.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 41.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=6bbc09129673c6fdfc238045f8fb88420b67553de6b45421b3705a0913878bb9\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKuLtghTquOB",
        "outputId": "c7139493-d536-4f6d-f837-dfa82c634cb6"
      },
      "source": [
        "pip install pytorch_transformers\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch_transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/b7/d3d18008a67e0b968d1ab93ad444fc05699403fa662f634b2f2c318a508b/pytorch_transformers-1.2.0-py3-none-any.whl (176kB)\n",
            "\r\u001b[K     |█▉                              | 10kB 17.0MB/s eta 0:00:01\r\u001b[K     |███▊                            | 20kB 22.0MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 30kB 11.9MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 40kB 10.5MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 51kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 61kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 71kB 6.5MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 81kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 92kB 6.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 102kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 112kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 122kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 133kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 143kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 153kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 163kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 174kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 184kB 6.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (1.7.0+cu101)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 12.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (1.19.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (2.23.0)\n",
            "Collecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b3/f4/f9ab9845a63cef64d42dea7ef09c593be5ec2b627d398ef7a0954ac0a8f7/boto3-1.16.49-py2.py3-none-any.whl (130kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 26.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (0.0.43)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->pytorch_transformers) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->pytorch_transformers) (0.8)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->pytorch_transformers) (0.16.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_transformers) (2.10)\n",
            "Collecting s3transfer<0.4.0,>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/79/e6afb3d8b0b4e96cefbdc690f741d7dd24547ff1f94240c997a26fa908d3/s3transfer-0.3.3-py2.py3-none-any.whl (69kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 6.7MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Collecting botocore<1.20.0,>=1.19.49\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/b9/d4118f2befea084c9bc72aaa9cb10f1cef8311a534cfdc10e02715baa121/botocore-1.19.49-py2.py3-none-any.whl (7.2MB)\n",
            "\u001b[K     |████████████████████████████████| 7.2MB 19.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch_transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch_transformers) (1.0.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch_transformers) (7.1.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.20.0,>=1.19.49->boto3->pytorch_transformers) (2.8.1)\n",
            "\u001b[31mERROR: botocore 1.19.49 has requirement urllib3<1.27,>=1.25.4; python_version != \"3.4\", but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: sentencepiece, jmespath, botocore, s3transfer, boto3, pytorch-transformers\n",
            "Successfully installed boto3-1.16.49 botocore-1.19.49 jmespath-0.10.0 pytorch-transformers-1.2.0 s3transfer-0.3.3 sentencepiece-0.1.94\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "kSh8aU4yqy-7",
        "outputId": "14033a5f-07e2-441f-93e1-aa708fdd98cb"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/train.csv\")\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword  ...                                               text target\n",
              "0   1     NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n",
              "1   4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n",
              "2   5     NaN  ...  All residents asked to 'shelter in place' are ...      1\n",
              "3   6     NaN  ...  13,000 people receive #wildfires evacuation or...      1\n",
              "4   7     NaN  ...  Just got sent this photo from Ruby #Alaska as ...      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmmWjx22q9B2",
        "outputId": "f5da9ea3-e015-4de4-f312-a6d11cf83a9e"
      },
      "source": [
        "sentences = data.text.values\n",
        "sentences"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all',\n",
              "       'Forest fire near La Ronge Sask. Canada',\n",
              "       \"All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected\",\n",
              "       ...,\n",
              "       'M1.94 [01:04 UTC]?5km S of Volcano Hawaii. http://t.co/zDtoyd8EbJ',\n",
              "       'Police investigating after an e-bike collided with a car in Little Portugal. E-bike rider suffered serious non-life threatening injuries.',\n",
              "       'The Latest: More Homes Razed by Northern California Wildfire - ABC News http://t.co/YmY4rSkQ3d'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJZlmSnArtiA"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(data.index.values, \n",
        "                                                  data.target.values, \n",
        "                                                  test_size=0.15, \n",
        "                                                  random_state=42,\n",
        "                                                  stratify=data.target.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxWWryXjrxvo"
      },
      "source": [
        "data['data_type'] = ['not_set']*data.shape[0]\n",
        "data.loc[X_train, 'data_type'] = 'train'\n",
        "data.loc[X_val, 'data_type'] = 'validation'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xnk6ds1fr80K",
        "outputId": "123bbabf-8635-4841-e596-692ab3d9c409"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\n",
        "    'bert-base-uncased',\n",
        "    do_lower_case=True\n",
        ")\n",
        "\n",
        "import torch\n",
        "encoded_data_train = tokenizer.batch_encode_plus(\n",
        "    data[data.data_type=='train'].text.values,\n",
        "    add_special_tokens=True,\n",
        "    return_attention_mask=True,\n",
        "    pad_to_max_length=True,\n",
        "    max_length=256,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "encoded_data_val = tokenizer.batch_encode_plus(\n",
        "   data[data.data_type=='validation'].text.values,\n",
        "    add_special_tokens=True,\n",
        "    return_attention_mask=True,\n",
        "    pad_to_max_length=True,\n",
        "    max_length=256,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "input_ids_train = encoded_data_train['input_ids']\n",
        "attention_masks_train = encoded_data_train['attention_mask']\n",
        "labels_train = torch.tensor(data[data.data_type=='train'].target.values)\n",
        "\n",
        "input_ids_val = encoded_data_val['input_ids']\n",
        "attention_masks_val = encoded_data_val['attention_mask']\n",
        "labels_val = torch.tensor(data[data.data_type=='validation'].target.values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2179: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPkq5wv-s2-5"
      },
      "source": [
        "dataset_train = TensorDataset(input_ids_train, \n",
        "                              attention_masks_train,\n",
        "                              labels_train)\n",
        "\n",
        "dataset_val = TensorDataset(input_ids_val, \n",
        "                            attention_masks_val,\n",
        "                           labels_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlDHQE6Ls24F"
      },
      "source": [
        "from transformers import BertForSequenceClassification\n",
        "label_dict = {}\n",
        "possible_labels = data.target.unique()\n",
        "\n",
        "for index, possible_label in enumerate(possible_labels):\n",
        "    label_dict[possible_label] = index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225,
          "referenced_widgets": [
            "5a9f86de86a844b898c6f6964a2e1d20",
            "71a1e51334b148b6a366dae75d5978b2",
            "d75546bc627d412abd88021886a7ec3c",
            "cf35e5bc9b6f4681b1d6273f5ca576fa",
            "1d979e7c6fbb41a7a1a64964dabf5b55",
            "24955abf8c964edc82f62a4ce6a67018",
            "bb8fdef6f9ae4e32851b9adffe9d7a26",
            "e1dd0991907d40ada4bcd8b8da06089d",
            "8eee096fb24b4b9eb6e5cf6b49af185b",
            "34d1bca29bb346458bf4ca66c37f659a",
            "af9f3d2b29804c969dec834444631194",
            "4c603152ea374a1eb70bc9c444fe7140",
            "e3cd1a1a99ba43e29751522d6af1b25b",
            "d1f5f725ca314522a500abe833efa366",
            "2d1adcad72ed4a6aa32c0294eff74dc0",
            "76c2f25475634b5facd0cd82a54542f9"
          ]
        },
        "id": "v5XkKedCs2qT",
        "outputId": "43940ae4-eb2f-4638-cba7-d9529be4babd"
      },
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\n",
        "                                      'bert-base-uncased', \n",
        "                                      num_labels = len(label_dict),\n",
        "                                      output_attentions = False,\n",
        "                                      output_hidden_states = False\n",
        "                                     )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5a9f86de86a844b898c6f6964a2e1d20",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8eee096fb24b4b9eb6e5cf6b49af185b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sA9HeMUtXsr"
      },
      "source": [
        "batch_size = 4\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "dataloader_train = DataLoader(\n",
        "    dataset_train,\n",
        "    sampler=RandomSampler(dataset_train),\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "dataloader_val = DataLoader(\n",
        "    dataset_val,\n",
        "    sampler=RandomSampler(dataset_val),\n",
        "    batch_size=32\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhQ0ifOBtjBd"
      },
      "source": [
        "from transformers import AdamW\n",
        "optimizer = AdamW(\n",
        "    model.parameters(),\n",
        "    lr = 1e-5,\n",
        "    eps = 1e-8\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAPGLkfFtl8t"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "epochs = 1\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps = len(dataloader_train)*epochs\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCW9GCp3touM"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuPatpxLtqwV"
      },
      "source": [
        " def f1_score_func(preds, labels):\n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return f1_score(labels_flat, preds_flat, average = 'weighted') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6OB2FaUtr0c"
      },
      "source": [
        "def evaluate(dataloader_val):\n",
        "\n",
        "    model.eval()\n",
        "    \n",
        "    loss_val_total = 0\n",
        "    predictions, true_vals = [], []\n",
        "    \n",
        "    for batch in tqdm(dataloader_val):\n",
        "        \n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        \n",
        "        inputs = {'input_ids':      batch[0],\n",
        "                  'attention_mask': batch[1],\n",
        "                  'labels':         batch[2],\n",
        "                 }\n",
        "\n",
        "        with torch.no_grad():        \n",
        "            outputs = model(**inputs)\n",
        "            \n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "        loss_val_total += loss.item()\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = inputs['labels'].cpu().numpy()\n",
        "        predictions.append(logits)\n",
        "        true_vals.append(label_ids)\n",
        "    \n",
        "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
        "    \n",
        "    predictions = np.concatenate(predictions, axis=0)\n",
        "    true_vals = np.concatenate(true_vals, axis=0)\n",
        "            \n",
        "    return loss_val_avg, predictions, true_vals"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0J20fHR6t3kZ",
        "outputId": "3471c90a-b804-4cff-e054-0c6e449fd8b8"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "72531f336b6a47f2b24e9b2db9012766",
            "ce3500d79f3a4f64909ec7cadfa771fd",
            "f7e3c265e3e34f2e851123792f5c0a2e",
            "bde6f94953a44e5f8b5b244531995171",
            "ac9c369a3cab4b7c8ee76eba3fc42446",
            "961d5ad2dd0440008b6d8cc4e389bb85",
            "085cefd98ee14ce9ad4f4ea27c2c7530",
            "930a9c78ce55442ea7ecea642f96ccca",
            "f1557024adf24d25b2de01c994b9984d",
            "0772b5515f5e4e62a4fc4eb32a94593d",
            "c2b03216c9ba4ec7b2799f0b6817e019",
            "e6f07915d7af4ca68f683dc625956b89",
            "21b05171a7854e46a4d20e21d7abbefa",
            "cc89cc57b36e487683ec6131306d7881",
            "44ad8887d2124502a1576a3d17244caf",
            "63ead6a3ace5458585f8b2a4250e293a"
          ]
        },
        "id": "i5JmPpKuuCjU",
        "outputId": "1fa2e0fd-97b1-4446-9594-f9667dd7b7ef"
      },
      "source": [
        "from tqdm.notebook import tqdm\n",
        "\n",
        "for epoch in tqdm(range(1, epochs+1)):\n",
        "    model.train()\n",
        "    loss_train_total = 0\n",
        "    \n",
        "    progress_bar = tqdm(dataloader_train, \n",
        "                        desc='Epoch {:1d}'.format(epoch), \n",
        "                        leave=False, \n",
        "                        disable=False)\n",
        "    \n",
        "    for batch in progress_bar:\n",
        "        model.zero_grad()\n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        inputs = {\n",
        "            'input_ids': batch[0],\n",
        "            'attention_mask': batch[1],\n",
        "            'labels': batch[2]\n",
        "        }\n",
        "        \n",
        "        outputs = model(**inputs)\n",
        "        loss = outputs[0]\n",
        "        loss_train_total +=loss.item()\n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        \n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        \n",
        "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})     \n",
        "    \n",
        "    #torch.save(model.state_dict(), f'Models/BERT_ft_Epoch{epoch}.model')\n",
        "    \n",
        "\n",
        "    \n",
        "    loss_train_avg = loss_train_total/len(dataloader_train)\n",
        "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
        "    \n",
        "    val_loss, predictions, true_vals = evaluate(dataloader_val)\n",
        "    val_f1 = f1_score_func(predictions, true_vals)\n",
        "    print(f'Validation loss: {val_loss}')\n",
        "    print(f'F1 Score (weighted): {val_f1}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "72531f336b6a47f2b24e9b2db9012766",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f1557024adf24d25b2de01c994b9984d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Epoch 1', max=1618.0, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBML7PtyvBjx"
      },
      "source": [
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}